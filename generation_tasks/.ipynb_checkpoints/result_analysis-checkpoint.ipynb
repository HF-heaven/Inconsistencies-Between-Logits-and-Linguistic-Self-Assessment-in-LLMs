{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73097f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import config\n",
    "import numpy as np\n",
    "\n",
    "def calculate_ece(confidences, correct):\n",
    "    M = 10 # 11 bins: 0,1,...,10\n",
    "    ece = 0.0\n",
    "    n = len(confidences)\n",
    "    bins = np.linspace(0.0, 10.0, M+1)\n",
    "\n",
    "    for i in range(M):\n",
    "        bin_lower, bin_upper = bins[i], bins[i+1]\n",
    "        if M == 0:\n",
    "            in_bin = (confidences >= bin_lower) & (confidences <= bin_upper)\n",
    "        else:\n",
    "            in_bin = (confidences > bin_lower) & (confidences <= bin_upper)\n",
    "        bin_size = np.sum(in_bin)\n",
    "        if bin_size > 0:\n",
    "            conf_avg = np.mean(confidences[in_bin])\n",
    "            norm_conf_avg = conf_avg / 10.0\n",
    "            acc_avg = np.mean(correct[in_bin])\n",
    "            ece += (bin_size / n) * np.abs(acc_avg - norm_conf_avg)\n",
    "\n",
    "    return ece\n",
    "\n",
    "\n",
    "def calculate_coefficient(run_name, model):\n",
    "    loaded_df = pd.read_csv(f'{config.output_dir}/sequences/{run_name}/{model.split(\"/\")[-1]}_conf_uncertainty.csv')\n",
    "\n",
    "    loaded_df['pred_entropy'] = pd.to_numeric(loaded_df['predictive_entropy_over_concepts'], errors='coerce')\n",
    "    loaded_df['unnorm_entropy'] = pd.to_numeric(loaded_df['unnormalised_entropy_over_concepts'], errors='coerce')\n",
    "    loaded_df['confidence_list'] = pd.to_numeric(loaded_df['confidence_list'], errors='coerce')\n",
    "    loaded_df.replace('N/A', pd.NA, inplace=True)\n",
    "\n",
    "    loaded_df.dropna(subset=['pred_entropy', 'unnorm_entropy', 'confidence_list'], inplace=True)\n",
    "\n",
    "    correlation_norm = -loaded_df['pred_entropy'].corr(loaded_df['confidence_list'])\n",
    "    correlation_norm_exp = loaded_df['pred_entropy'].corr(np.exp(-loaded_df['confidence_list']))\n",
    "    correlation_unnorm = -loaded_df['unnorm_entropy'].corr(loaded_df['confidence_list'])    \n",
    "\n",
    "    return correlation_norm, correlation_norm_exp, correlation_unnorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a53c49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: coqa\n",
      "Model: Llama-2-7b-hf                      \t\t0.0561081563066567\n",
      "Model: Llama-2-7b-chat-hf                 \t\t0.06329734579658147\n",
      "Model: Llama-2-13b-hf                     \t\t-0.1476137415084034\n",
      "Model: Llama-2-13b-chat-hf                \t\t0.06381314925818411\n",
      "Model: Llama-3.1-8B                       \t\t-0.014993740494461947\n",
      "Model: Meta-Llama-3.1-8B-Instruct         \t\t0.16069363725679345\n",
      "Model: Llama-3.2-3B                       \t\t0.00041257492381514816\n",
      "Model: Llama-3.2-3B-Instruct              \t\t0.24495199899299497\n",
      "Model: Meta-Llama-3-8B                    \t\t0.00779846309196965\n",
      "Model: Meta-Llama-3-8B-Instruct           \t\t-0.005993927385860379\n",
      "Model: Qwen2.5-14B                        \t\t0.004234559052747409\n",
      "Model: Qwen2.5-14B-Instruct               \t\t0.14069474788850225\n",
      "Model: Qwen2.5-3B                         \t\t-0.21067532350485618\n",
      "Model: Qwen2.5-3B-Instruct                \t\t-0.03240709438383913\n",
      "Model: Qwen3-4B-Base                      \t\t-0.6403238717956943\n",
      "Model: Qwen3-4B-Instruct-2507             \t\tnan\n",
      "Model: Qwen3-8B-Base                      \t\tnan\n",
      "Model: Qwen3-14B-Base                     \t\tnan\n",
      "Model: Mistral-7B-v0.1                    \t\t-0.039925215011316156\n",
      "Model: Mistral-7B-Instruct-v0.1           \t\t-0.01703488908217734\n",
      "Model: Mistral-7B-v0.2                    \t\t-0.008296776993900707\n",
      "Model: Mistral-7B-Instruct-v0.2           \t\t0.21343577363992294\n",
      "Model: Mistral-7B-v0.3                    \t\t-0.04772133159332401\n",
      "Model: Mistral-7B-Instruct-v0.3           \t\t0.011994316515661862\n",
      "Model: Mistral-Nemo-Base-2407             \t\t-0.050440301226112344\n",
      "Model: Mistral-Nemo-Instruct-2407         \t\t-0.015448048929053533\n",
      "Model: Mixtral-8x7B-v0.1                  \t\t-0.024493321069006476\n",
      "Model: Mixtral-8x7B-Instruct-v0.1         \t\t0.07669921485989988\n",
      "--------------------------------------------------------------------------------\n",
      "Task: trivia_qa\n",
      "Model: Llama-2-7b-hf                      \t\t0.21064925823256112\n",
      "Model: Llama-2-7b-chat-hf                 \t\t0.4328091660661709\n",
      "Model: Llama-2-13b-hf                     \t\t0.22367956548387496\n",
      "Model: Llama-2-13b-chat-hf                \t\t0.46904940244232496\n",
      "Model: Llama-3.1-8B                       \t\t0.004038929222793688\n",
      "Model: Meta-Llama-3.1-8B-Instruct         \t\t0.3181541987822229\n",
      "Model: Llama-3.2-3B                       \t\t0.2609320670816326\n",
      "Model: Llama-3.2-3B-Instruct              \t\t0.5909874575717166\n",
      "Model: Meta-Llama-3-8B                    \t\t-0.03357634233853712\n",
      "Model: Meta-Llama-3-8B-Instruct           \t\t0.15327925652468774\n",
      "Model: Qwen2.5-14B                        \t\tnan\n",
      "Model: Qwen2.5-14B-Instruct               \t\tnan\n",
      "Model: Qwen2.5-3B                         \t\tnan\n",
      "Model: Qwen2.5-3B-Instruct                \t\tnan\n",
      "Model: Qwen3-4B-Base                      \t\tnan\n",
      "Model: Qwen3-4B-Instruct-2507             \t\tnan\n",
      "Model: Qwen3-8B-Base                      \t\tnan\n",
      "Model: Qwen3-14B-Base                     \t\tnan\n",
      "Model: Mistral-7B-v0.1                    \t\t0.2882841053545693\n",
      "Model: Mistral-7B-Instruct-v0.1           \t\t0.39173090060428645\n",
      "Model: Mistral-7B-v0.2                    \t\t0.25080408631309214\n",
      "Model: Mistral-7B-Instruct-v0.2           \t\t0.33782299143454314\n",
      "Model: Mistral-7B-v0.3                    \t\t0.032535559885822\n",
      "Model: Mistral-7B-Instruct-v0.3           \t\t0.548715660892618\n",
      "Model: Mistral-Nemo-Base-2407             \t\t0.3553927522528673\n",
      "Model: Mistral-Nemo-Instruct-2407         \t\t0.47184508996783964\n",
      "Model: Mixtral-8x7B-v0.1                  \t\t0.3461192791066691\n",
      "Model: Mixtral-8x7B-Instruct-v0.1         \t\t0.33372945569367846\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "run_name = {\n",
    "    \"deft-monkey-51\": \"coqa\",\n",
    "    \"decent-field-17\": \"trivia_qa\"\n",
    "}\n",
    "\n",
    "model = \"meta-llama/Llama-2-7b-hf\"\n",
    "models = [\n",
    "    \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    \"meta-llama/Llama-2-13b-hf\",\n",
    "    \"meta-llama/Llama-2-13b-chat-hf\",\n",
    "    \"meta-llama/Llama-3.1-8B\",\n",
    "    \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    \"meta-llama/Llama-3.2-3B\",\n",
    "    \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    \"meta-llama/Meta-Llama-3-8B\",\n",
    "    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "\n",
    "    \"Qwen/Qwen2.5-14B\",\n",
    "    \"Qwen/Qwen2.5-14B-Instruct\",\n",
    "    \"Qwen/Qwen2.5-3B\",\n",
    "    \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "\n",
    "    \"Qwen/Qwen3-4B-Base\",\n",
    "    \"Qwen/Qwen3-4B-Instruct-2507\",\n",
    "    \"Qwen/Qwen3-8B-Base\",\n",
    "    \"Qwen/Qwen3-14B-Base\",\n",
    "\n",
    "    \"mistralai/Mistral-7B-v0.1\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    \"mistral-community/Mistral-7B-v0.2\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    \"mistralai/Mistral-7B-v0.3\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    \"mistralai/Mistral-Nemo-Base-2407\",\n",
    "    \"mistralai/Mistral-Nemo-Instruct-2407\",\n",
    "\n",
    "    \"mistralai/Mixtral-8x7B-v0.1\",\n",
    "    \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "]\n",
    "for run_id in run_name.keys():\n",
    "    task = run_name[run_id]\n",
    "    print(f\"Task: {task}\")\n",
    "    for model in models:\n",
    "        # print(f\"Model: {model}\")\n",
    "        correlation_norm, correlation_norm_exp, correlation_unnorm = calculate_coefficient(run_id, model)\n",
    "        print(f\"Model: {model.split('/')[1]:<35}\\t\\t{correlation_norm}\")\n",
    "    print(\"-\" * 80) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
